/**
 * AI æœåŠ¡æ¨¡å—
 * 
 * æä¾›ä¸å„ç±» AI æ¨¡å‹ï¼ˆOpenAIã€Anthropicã€è‡ªå®šä¹‰ï¼‰çš„äº¤äº’èƒ½åŠ›ï¼Œ
 * ç”¨äºæ‰§è¡Œä»£ç å®¡æŸ¥å¹¶è§£æå®¡æŸ¥ç»“æœã€‚
 */

import { createOpenAI } from '@ai-sdk/openai'
import { createAnthropic } from '@ai-sdk/anthropic'
import { streamText, generateText } from 'ai'
import OpenAI from 'openai'
import type { AIModelConfig, ReviewSeverity } from '@/lib/types'
import { SYSTEM_PROMPT } from '@/lib/prompts'

/**
 * å®¡æŸ¥è¯„è®ºæ¥å£
 */
export interface ReviewComment {
  /** æ–‡ä»¶è·¯å¾„ */
  filePath: string
  /** è¡Œå· */
  lineNumber: number
  /** è¡Œå·èŒƒå›´ç»“æŸï¼ˆå¯é€‰ï¼‰ */
  lineRangeEnd?: number
  /** ä¸¥é‡çº§åˆ« */
  severity: ReviewSeverity
  /** è¯„è®ºå†…å®¹ */
  content: string
  /** diff ä»£ç å—ï¼ˆå¯é€‰ï¼‰ */
  diffHunk?: string
}

/**
 * AI æœåŠ¡ç±»
 * 
 * å°è£…äº†ä¸ AI æ¨¡å‹äº¤äº’çš„æ‰€æœ‰é€»è¾‘ï¼Œæ”¯æŒï¼š
 * - OpenAI (GPT-4o, GPT-4 Turbo ç­‰)
 * - Anthropic Claude (Claude 3.5 Sonnet ç­‰)
 * - è‡ªå®šä¹‰ OpenAI å…¼å®¹ API (å¦‚æ™ºè°± GLMã€æœ¬åœ° Ollama)
 */
export class AIService {
  /**
   * æ‰§è¡Œä»£ç å®¡æŸ¥
   */
  async reviewCode(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    try {
      // è‡ªå®šä¹‰æ¨¡å‹ä½¿ç”¨ OpenAI SDK ç›´æ¥è°ƒç”¨ï¼Œé¿å… Vercel AI SDK å…¼å®¹æ€§é—®é¢˜
      if (modelConfig.provider === 'custom') {
        return await this.reviewCodeWithOpenAISDK(prompt, modelConfig)
      }

      let model

      switch (modelConfig.provider) {
        case 'openai':
          const openaiClient = createOpenAI({ apiKey: modelConfig.apiKey })
          model = openaiClient(modelConfig.modelId)
          break
        case 'claude':
          const anthropicClient = createAnthropic({ apiKey: modelConfig.apiKey })
          model = anthropicClient(modelConfig.modelId)
          break
        default:
          throw new Error(`Unsupported AI provider: ${modelConfig.provider}`)
      }

      const response = await generateText({
        model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: prompt },
        ],
      })

      console.log('AI Response type:', typeof response)
      console.log('AI Response keys:', Object.keys(response))

      if (response.text) {
        return response.text
      }

      console.error('Unexpected AI response format:', response)
      throw new Error('Unexpected AI response format')
    } catch (error) {
      console.error('AI review failed:', error)
      throw new Error('Failed to generate AI review')
    }
  }

  /**
   * ä½¿ç”¨ OpenAI SDK è°ƒç”¨è‡ªå®šä¹‰æ¨¡å‹
   * æ ¹æ® API ç«¯ç‚¹è‡ªåŠ¨åˆ¤æ–­ä½¿ç”¨ OpenAI è¿˜æ˜¯ Anthropic æ ¼å¼
   */
  private async reviewCodeWithOpenAISDK(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    console.log('ğŸ”§ Using custom API for model:', modelConfig.modelId)
    console.log('ğŸ”§ API Endpoint:', modelConfig.apiEndpoint)

    const isAnthropicFormat = modelConfig.apiEndpoint?.includes('anthropic')

    if (isAnthropicFormat) {
      return await this.callAnthropicAPI(prompt, modelConfig, systemPrompt)
    } else {
      return await this.callOpenAIAPI(prompt, modelConfig, systemPrompt)
    }
  }

  /**
   * è°ƒç”¨ OpenAI å…¼å®¹ API
   */
  private async callOpenAIAPI(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    const client = new OpenAI({
      apiKey: modelConfig.apiKey,
      baseURL: modelConfig.apiEndpoint,
    })

    const response = await client.chat.completions.create({
      model: modelConfig.modelId,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: prompt },
      ],
      max_tokens: modelConfig.maxTokens || 4096,
      temperature: modelConfig.temperature || 0.3,
    })

    console.log('âœ… OpenAI API Response received')
    console.log('ğŸ“Š Usage:', response.usage)

    const content = response.choices[0]?.message?.content
    if (!content) {
      console.error('Empty response from OpenAI API:', response)
      throw new Error('Empty response from OpenAI API')
    }

    return content
  }

  /**
   * è°ƒç”¨ Anthropic å…¼å®¹ APIï¼ˆæ”¯æŒé‡è¯•ï¼‰
   */
  private async callAnthropicAPI(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT,
    retries = 3
  ): Promise<string> {
    // æ™ºèƒ½å¤„ç† API ç«¯ç‚¹
    let apiUrl = modelConfig.apiEndpoint || ''
    if (!apiUrl.endsWith('/v1/messages')) {
      apiUrl = apiUrl.replace(/\/$/, '')
      apiUrl = `${apiUrl}/v1/messages`
    }

    console.log('ğŸ”— Anthropic API URL:', apiUrl)

    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        const response = await fetch(apiUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'x-api-key': modelConfig.apiKey,
            'anthropic-version': '2023-06-01',
          },
          body: JSON.stringify({
            model: modelConfig.modelId,
            max_tokens: modelConfig.maxTokens || 4096,
            system: systemPrompt,
            messages: [{ role: 'user', content: prompt }],
          }),
        })

        if (!response.ok) {
          const errorText = await response.text()
          console.error('Anthropic API error:', response.status, errorText)
          throw new Error(`Anthropic API error: ${response.status}`)
        }

        const data = await response.json()

        console.log('âœ… Anthropic API Response received')
        console.log('ğŸ“Š Usage:', data.usage)
        console.log('ğŸ“‹ Response structure:', Object.keys(data))

        // Anthropic å“åº”æ ¼å¼: { content: [{ type: "text", text: "..." }] }
        if (data.content && Array.isArray(data.content) && data.content.length > 0) {
          const textContent = data.content.find((c: { type: string }) => c.type === 'text')
          if (textContent?.text) {
            return textContent.text
          }
        }

        console.error('Unexpected Anthropic response format:', JSON.stringify(data, null, 2))
        throw new Error('Unexpected Anthropic response format')
      } catch (error) {
        console.error(`âŒ Attempt ${attempt}/${retries} failed:`, error)

        if (attempt < retries) {
          const delay = attempt * 2000
          console.log(`â³ Retrying in ${delay / 1000}s...`)
          await new Promise((resolve) => setTimeout(resolve, delay))
        } else {
          throw error
        }
      }
    }

    throw new Error('All retry attempts failed')
  }

  /**
   * æµå¼ä»£ç å®¡æŸ¥ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰
   */
  async streamReviewCode(
    prompt: string,
    modelConfig: AIModelConfig,
    onChunk?: (chunk: string) => void
  ): Promise<string> {
    try {
      let model

      switch (modelConfig.provider) {
        case 'openai':
          const openaiClient = createOpenAI({
            apiKey: modelConfig.apiKey,
          })
          model = openaiClient(modelConfig.modelId)
          break
        case 'claude':
          const anthropicClient = createAnthropic({
            apiKey: modelConfig.apiKey,
          })
          model = anthropicClient(modelConfig.modelId)
          break
        case 'custom':
          const customClient = createOpenAI({
            apiKey: modelConfig.apiKey,
            baseURL: modelConfig.apiEndpoint,
          })
          model = customClient(modelConfig.modelId)
          break
        default:
          throw new Error(`Unsupported AI provider: ${modelConfig.provider}`)
      }

      const result = await streamText({
        model,
        prompt,
      })

      let fullText = ''
      for await (const chunk of result.textStream) {
        fullText += chunk
        if (onChunk) {
          onChunk(chunk)
        }
      }

      await result.text // ç­‰å¾…å®Œæˆ
      return fullText
    } catch (error) {
      console.error('AI streaming review failed:', error)
      throw new Error('Failed to stream AI review')
    }
  }

  /**
   * è§£æ AI è¿”å›çš„å®¡æŸ¥è¯„è®º
   * 
   * æ”¯æŒæ ¼å¼ï¼š
   * - `è¡Œå·: [çº§åˆ«] å†…å®¹`
   * - `è¡Œå·-è¡Œå·: [çº§åˆ«] å†…å®¹`
   */
  parseReviewComments(aiResponse: string, filePath: string): ReviewComment[] {
    const comments: ReviewComment[] = []
    const lines = aiResponse.split('\n')
    let currentComment: Partial<ReviewComment> = {}
    let currentContent: string[] = []
    let inCodeBlock = false

    const lineStartPattern = /^(\d+)(?:-(\d+))?:\s*(.*)$/

    for (let i = 0; i < lines.length; i++) {
      const line = lines[i]
      const lineMatch = line.match(lineStartPattern)

      if (lineMatch) {
        // ä¿å­˜ä¹‹å‰çš„è¯„è®º
        if (currentComment.lineNumber && currentContent.length > 0) {
          const content = this.cleanCommentContent(currentContent.join('\n').trim())
          if (content && content !== 'LGTM!') {
            comments.push({
              filePath,
              lineNumber: currentComment.lineNumber,
              lineRangeEnd: currentComment.lineRangeEnd,
              severity: currentComment.severity || 'normal',
              content,
            } as ReviewComment)
          }
        }

        const restOfLine = lineMatch[3] || ''
        currentComment = {
          lineNumber: parseInt(lineMatch[1]),
          lineRangeEnd: lineMatch[2] ? parseInt(lineMatch[2]) : undefined,
          severity: this.inferSeverity(restOfLine || line),
        }
        currentContent = []
        inCodeBlock = false

        if (restOfLine.trim()) {
          currentContent.push(restOfLine)
        }
      } else if (currentComment.lineNumber) {
        if (line.startsWith('```')) {
          inCodeBlock = !inCodeBlock
        }
        currentContent.push(line)
      }
    }

    // ä¿å­˜æœ€åä¸€ä¸ªè¯„è®º
    if (currentComment.lineNumber && currentContent.length > 0) {
      const content = this.cleanCommentContent(currentContent.join('\n').trim())
      if (content && content !== 'LGTM!') {
        comments.push({
          filePath,
          lineNumber: currentComment.lineNumber,
          lineRangeEnd: currentComment.lineRangeEnd,
          severity: currentComment.severity || 'normal',
          content,
        } as ReviewComment)
      }
    }

    return comments
  }

  /**
   * è§£æâ€œæ€»ç»“ä¼˜å…ˆâ€çš„å®¡æŸ¥è¾“å‡ºï¼š
   * - ç»Ÿè®¡è¡Œï¼ˆä¸¥æ ¼ï¼‰ï¼š`ç»Ÿè®¡: ä¸¥é‡=<n> ä¸€èˆ¬=<n> å»ºè®®=<n>`
   * - ä»…å±•å¼€ä¸¥é‡é—®é¢˜ï¼ˆå¯é€‰ï¼‰ï¼š`- path/to/file:12-15 é—®é¢˜æè¿°`
   *
   * ä¸ºå…¼å®¹æ—§è¾“å‡ºï¼Œä¹Ÿä¼šå°è¯•ä» `è¡Œå·: [ä¸¥é‡/ä¸€èˆ¬/å»ºè®®] ...` ä¸­æ¨æ–­ç»Ÿè®¡å’Œä¸¥é‡é¡¹ã€‚
   */
  parseReviewSummary(
    aiResponse: string,
    options?: { defaultFilePath?: string; maxCriticalItems?: number }
  ): {
    counts: { critical: number; normal: number; suggestion: number }
    criticalItems: Array<{
      filePath: string
      lineNumber: number
      lineRangeEnd?: number
      content: string
    }>
  } {
    const defaultFilePath = options?.defaultFilePath
    const maxCriticalItems = options?.maxCriticalItems ?? 12

    const counts = { critical: 0, normal: 0, suggestion: 0 }
    const criticalItems: Array<{
      filePath: string
      lineNumber: number
      lineRangeEnd?: number
      content: string
    }> = []

    const text = aiResponse || ''
    const lines = text.split('\n')

    // 1) Parse strict counts line
    // Examples:
    // - ç»Ÿè®¡: ä¸¥é‡=1 ä¸€èˆ¬=2 å»ºè®®=3
    // - ç»Ÿè®¡ï¼šä¸¥é‡ 1ï¼Œä¸€èˆ¬ 2ï¼Œå»ºè®® 3
    // - Counts: Critical=1 Normal=2 Suggestion=3
    const countsLine =
      text.match(
        /(?:^|\n)\s*(?:ç»Ÿè®¡|Counts)\s*[:ï¼š]\s*([^\n]+)\n?/i
      )?.[1] ?? ''
    if (countsLine) {
      const zh = countsLine.match(
        /ä¸¥é‡\s*=?\s*(\d+)[^\d]+ä¸€èˆ¬\s*=?\s*(\d+)[^\d]+å»ºè®®\s*=?\s*(\d+)/
      )
      const en = countsLine.match(
        /critical\s*=?\s*(\d+)[^\d]+normal\s*=?\s*(\d+)[^\d]+suggestion\s*=?\s*(\d+)/i
      )
      const m = zh || en
      if (m) {
        counts.critical = Number(m[1] ?? 0)
        counts.normal = Number(m[2] ?? 0)
        counts.suggestion = Number(m[3] ?? 0)
      }
    }

    // 2) Parse expanded critical list items
    // Example: - apps/foo.ts:19-21 xxx
    const criticalItemPattern =
      /^\s*(?:[-*]|\d+\.)\s*`?([^\s`:]+(?:\/[^\s`:]+)*)`?:(\d+)(?:-(\d+))?\s+(.+?)\s*$/

    for (const line of lines) {
      if (criticalItems.length >= maxCriticalItems) break
      const m = line.match(criticalItemPattern)
      if (!m) continue
      const filePath = m[1]
      const lineNumber = Number(m[2])
      const lineRangeEnd = m[3] ? Number(m[3]) : undefined
      const content = m[4].trim()
      if (!filePath || !lineNumber || !content) continue
      criticalItems.push({ filePath, lineNumber, lineRangeEnd, content })
    }

    // 3) Fallback for old style output: file headings + `line: [ä¸¥é‡/ä¸€èˆ¬/å»ºè®®] ...`
    if (!countsLine || (counts.critical === 0 && counts.normal === 0 && counts.suggestion === 0)) {
      let currentFile = defaultFilePath || ''
      const fileHeadingPattern = /^\s*([A-Za-z0-9_.-]+(?:\/[A-Za-z0-9_.-]+)+\.[A-Za-z0-9]+)\s*$/
      const oldItemPattern = /^(\d+)(?:-(\d+))?:\s*(.*)$/

      for (const rawLine of lines) {
        const line = rawLine.trim()
        if (!line) continue

        const fileM = line.match(fileHeadingPattern)
        if (fileM) {
          currentFile = fileM[1]
          continue
        }

        const itemM = line.match(oldItemPattern)
        if (!itemM) continue
        const rest = itemM[3] || ''
        const severity = this.inferSeverity(rest || line)
        if (severity === 'critical') counts.critical += 1
        else if (severity === 'suggestion') counts.suggestion += 1
        else counts.normal += 1

        if (severity === 'critical' && criticalItems.length < maxCriticalItems) {
          const content = this.cleanCommentContent(rest).trim()
          if (content && content !== 'LGTM!') {
            const lineNumber = Number(itemM[1])
            const lineRangeEnd = itemM[2] ? Number(itemM[2]) : undefined
            const filePath = currentFile || defaultFilePath || 'unknown'
            criticalItems.push({ filePath, lineNumber, lineRangeEnd, content })
          }
        }
      }
    }

    return { counts, criticalItems }
  }

  /**
   * æ¸…ç†è¯„è®ºå†…å®¹ï¼Œç§»é™¤çº§åˆ«æ ‡ç­¾å‰ç¼€
   */
  private cleanCommentContent(content: string): string {
    return content
      .replace(/^\[ä¸¥é‡\]\s*/i, '')
      .replace(/^\[ä¸€èˆ¬\]\s*/i, '')
      .replace(/^\[å»ºè®®\]\s*/i, '')
      .replace(/^\[Critical\]\s*/i, '')
      .replace(/^\[Normal\]\s*/i, '')
      .replace(/^\[Suggestion\]\s*/i, '')
      .trim()
  }

  /**
   * ä»è¯„è®ºå†…å®¹æ¨æ–­ä¸¥é‡çº§åˆ«
   */
  private inferSeverity(content: string): ReviewSeverity {
    const lowerContent = content.toLowerCase()

    // åŒ¹é…æ˜ç¡®çš„æ ‡ç­¾
    if (content.includes('[ä¸¥é‡]') || content.includes('[Critical]')) return 'critical'
    if (content.includes('[å»ºè®®]') || content.includes('[Suggestion]')) return 'suggestion'
    if (content.includes('[ä¸€èˆ¬]') || content.includes('[Normal]')) return 'normal'

    // å…³é”®è¯åŒ¹é…
    if (
      lowerContent.includes('ä¸¥é‡') ||
      lowerContent.includes('critical') ||
      lowerContent.includes('security') ||
      lowerContent.includes('vulnerability') ||
      lowerContent.includes('bug') ||
      lowerContent.includes('error') ||
      lowerContent.includes('breaking')
    ) {
      return 'critical'
    }

    if (
      lowerContent.includes('å»ºè®®') ||
      lowerContent.includes('suggestion') ||
      lowerContent.includes('consider') ||
      lowerContent.includes('could') ||
      lowerContent.includes('might')
    ) {
      return 'suggestion'
    }

    return 'normal'
  }
}

export const aiService = new AIService()
