import { createOpenAI } from '@ai-sdk/openai'
import { createAnthropic } from '@ai-sdk/anthropic'
import { streamText, generateText } from 'ai'
import OpenAI from 'openai'
import type { AIModelConfig, ReviewSeverity } from '@/lib/types'
import { SYSTEM_PROMPT } from '@/lib/prompts'

export interface ReviewComment {
  filePath: string
  lineNumber: number
  lineRangeEnd?: number
  severity: ReviewSeverity
  content: string
  diffHunk?: string
}

export class AIService {
  /**
   * ä»£ç å®¡æŸ¥æ–¹æ³•
   * @param prompt - ç”¨æˆ·æç¤ºè¯ï¼ˆå…·ä½“çš„å®¡æŸ¥å†…å®¹ï¼‰
   * @param modelConfig - AI æ¨¡å‹é…ç½®
   * @param systemPrompt - å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆé»˜è®¤ä½¿ç”¨å†…ç½® SYSTEM_PROMPTï¼‰
   */
  async reviewCode(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    try {
      // å¯¹äºè‡ªå®šä¹‰æ¨¡å‹ï¼ˆå¦‚æ™ºè°± GLMï¼‰ï¼Œç›´æ¥ä½¿ç”¨ OpenAI SDK è°ƒç”¨
      // å› ä¸º Vercel AI SDK å¯¹æŸäº› OpenAI å…¼å®¹ API çš„å“åº”æ ¼å¼å¤„ç†å¯èƒ½æœ‰é—®é¢˜
      if (modelConfig.provider === 'custom') {
        return await this.reviewCodeWithOpenAISDK(prompt, modelConfig)
      }

      let model

      switch (modelConfig.provider) {
        case 'openai':
          // åˆ›å»º OpenAI å®¢æˆ·ç«¯å®ä¾‹
          const openaiClient = createOpenAI({
            apiKey: modelConfig.apiKey,
          })
          model = openaiClient(modelConfig.modelId)
          break
        case 'claude':
          // åˆ›å»º Anthropic å®¢æˆ·ç«¯å®ä¾‹
          const anthropicClient = createAnthropic({
            apiKey: modelConfig.apiKey,
          })
          model = anthropicClient(modelConfig.modelId)
          break
        default:
          throw new Error(`Unsupported AI provider: ${modelConfig.provider}`)
      }

      // è°ƒç”¨ AI SDK çš„ generateText æ–¹æ³•ç”Ÿæˆæ–‡æœ¬
      // ä½¿ç”¨ messages æ ¼å¼ï¼Œåˆ†ç¦»ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
      const response = await generateText({
        model, // AI æ¨¡å‹å®ä¾‹
        messages: [
          { role: 'system', content: systemPrompt }, // ç³»ç»Ÿæç¤ºè¯ï¼šå®šä¹‰ AI è§’è‰²å’Œè¾“å‡ºæ ¼å¼
          { role: 'user', content: prompt }, // ç”¨æˆ·æç¤ºè¯ï¼šå…·ä½“çš„å®¡æŸ¥å†…å®¹
        ],
      })

      // æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜
      console.log('AI Response type:', typeof response)
      console.log('AI Response keys:', Object.keys(response))

      // AI SDK v6.x çš„ generateText è¿”å›å¯¹è±¡åŒ…å« text å±æ€§
      // ç›´æ¥è¿”å› response.text å³å¯è·å–ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
      if (response.text) {
        return response.text
      }

      // å¦‚æœ text å±æ€§ä¸å­˜åœ¨ï¼Œè®°å½•é”™è¯¯å¹¶æŠ›å‡ºå¼‚å¸¸
      console.error('Unexpected AI response format:', response)
      throw new Error('Unexpected AI response format')
    } catch (error) {
      console.error('AI review failed:', error)
      throw new Error('Failed to generate AI review')
    }
  }

  /**
   * ä½¿ç”¨åŸç”Ÿ HTTP è¯·æ±‚è°ƒç”¨è‡ªå®šä¹‰æ¨¡å‹
   * æ”¯æŒ OpenAI å’Œ Anthropic ä¸¤ç§å“åº”æ ¼å¼
   */
  private async reviewCodeWithOpenAISDK(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    console.log('ğŸ”§ Using custom API for model:', modelConfig.modelId)
    console.log('ğŸ”§ API Endpoint:', modelConfig.apiEndpoint)

    // åˆ¤æ–­æ˜¯å¦æ˜¯ Anthropic æ ¼å¼çš„ APIï¼ˆæ ¹æ® endpoint URL åˆ¤æ–­ï¼‰
    const isAnthropicFormat = modelConfig.apiEndpoint?.includes('anthropic')

    if (isAnthropicFormat) {
      // ä½¿ç”¨ Anthropic æ ¼å¼è°ƒç”¨
      return await this.callAnthropicAPI(prompt, modelConfig, systemPrompt)
    } else {
      // ä½¿ç”¨ OpenAI æ ¼å¼è°ƒç”¨
      return await this.callOpenAIAPI(prompt, modelConfig, systemPrompt)
    }
  }

  /**
   * è°ƒç”¨ OpenAI å…¼å®¹çš„ API
   */
  private async callOpenAIAPI(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    // åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼Œé…ç½®è‡ªå®šä¹‰ API ç«¯ç‚¹
    const client = new OpenAI({
      apiKey: modelConfig.apiKey,
      baseURL: modelConfig.apiEndpoint,
    })

    // è°ƒç”¨ chat completions API
    const response = await client.chat.completions.create({
      model: modelConfig.modelId,
      messages: [
        {
          role: 'system', // ç³»ç»Ÿæç¤ºè¯ï¼šå®šä¹‰ AI è§’è‰²å’Œè¾“å‡ºæ ¼å¼
          content: systemPrompt,
        },
        {
          role: 'user', // ç”¨æˆ·æç¤ºè¯ï¼šå…·ä½“çš„å®¡æŸ¥å†…å®¹
          content: prompt,
        },
      ],
      max_tokens: modelConfig.maxTokens || 4096,
      temperature: modelConfig.temperature || 0.3,
    })

    // æ‰“å°è°ƒè¯•ä¿¡æ¯
    console.log('âœ… OpenAI API Response received')
    console.log('ğŸ“Š Usage:', response.usage)

    // æå–å“åº”æ–‡æœ¬å†…å®¹
    const content = response.choices[0]?.message?.content
    if (!content) {
      console.error('Empty response from OpenAI API:', response)
      throw new Error('Empty response from OpenAI API')
    }

    return content
  }

  /**
   * è°ƒç”¨ Anthropic å…¼å®¹çš„ API
   * æ”¯æŒé‡è¯•æœºåˆ¶å¤„ç†ç½‘ç»œé—®é¢˜
   */
  private async callAnthropicAPI(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT,
    retries = 3
  ): Promise<string> {
    // æ™ºèƒ½å¤„ç† API ç«¯ç‚¹
    // å¦‚æœç«¯ç‚¹å·²åŒ…å« /v1/messages åˆ™ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™æ‹¼æ¥
    let apiUrl = modelConfig.apiEndpoint || ''
    if (!apiUrl.endsWith('/v1/messages')) {
      // ç§»é™¤æœ«å°¾æ–œæ 
      apiUrl = apiUrl.replace(/\/$/, '')
      apiUrl = `${apiUrl}/v1/messages`
    }

    console.log('ğŸ”— Anthropic API URL:', apiUrl)

    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        // æ„å»º Anthropic æ ¼å¼çš„è¯·æ±‚
        // Anthropic API ä½¿ç”¨ system å‚æ•°è€Œä¸æ˜¯ messages ä¸­çš„ system role
        const response = await fetch(apiUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'x-api-key': modelConfig.apiKey,
            'anthropic-version': '2023-06-01',
          },
          body: JSON.stringify({
            model: modelConfig.modelId,
            max_tokens: modelConfig.maxTokens || 4096,
            system: systemPrompt, // Anthropic çš„ç³»ç»Ÿæç¤ºè¯æ”¾åœ¨ system å‚æ•°ä¸­
            messages: [
              {
                role: 'user',
                content: prompt,
              },
            ],
          }),
        })

        if (!response.ok) {
          const errorText = await response.text()
          console.error('Anthropic API error:', response.status, errorText)
          throw new Error(`Anthropic API error: ${response.status}`)
        }

        const data = await response.json()

        // æ‰“å°è°ƒè¯•ä¿¡æ¯
        console.log('âœ… Anthropic API Response received')
        console.log('ğŸ“Š Usage:', data.usage)
        console.log('ğŸ“‹ Response structure:', Object.keys(data))

        // Anthropic å“åº”æ ¼å¼: { content: [{ type: "text", text: "..." }] }
        if (data.content && Array.isArray(data.content) && data.content.length > 0) {
          const textContent = data.content.find((c: { type: string }) => c.type === 'text')
          if (textContent?.text) {
            return textContent.text
          }
        }

        // å¦‚æœå“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œæ‰“å°å®Œæ•´å“åº”ç”¨äºè°ƒè¯•
        console.error('Unexpected Anthropic response format:', JSON.stringify(data, null, 2))
        throw new Error('Unexpected Anthropic response format')
      } catch (error) {
        console.error(`âŒ Attempt ${attempt}/${retries} failed:`, error)

        // å¦‚æœè¿˜æœ‰é‡è¯•æ¬¡æ•°ï¼Œç­‰å¾…åé‡è¯•
        if (attempt < retries) {
          const delay = attempt * 2000 // é€’å¢å»¶è¿Ÿ: 2s, 4s, 6s
          console.log(`â³ Retrying in ${delay / 1000}s...`)
          await new Promise((resolve) => setTimeout(resolve, delay))
        } else {
          throw error
        }
      }
    }

    throw new Error('All retry attempts failed')
  }

  async streamReviewCode(
    prompt: string,
    modelConfig: AIModelConfig,
    onChunk?: (chunk: string) => void
  ): Promise<string> {
    try {
      let model

      switch (modelConfig.provider) {
        case 'openai':
          const openaiClient = createOpenAI({
            apiKey: modelConfig.apiKey,
          })
          model = openaiClient(modelConfig.modelId)
          break
        case 'claude':
          const anthropicClient = createAnthropic({
            apiKey: modelConfig.apiKey,
          })
          model = anthropicClient(modelConfig.modelId)
          break
        case 'custom':
          const customClient = createOpenAI({
            apiKey: modelConfig.apiKey,
            baseURL: modelConfig.apiEndpoint,
          })
          model = customClient(modelConfig.modelId)
          break
        default:
          throw new Error(`Unsupported AI provider: ${modelConfig.provider}`)
      }

      const result = await streamText({
        model,
        prompt,
      })

      let fullText = ''
      for await (const chunk of result.textStream) {
        fullText += chunk
        if (onChunk) {
          onChunk(chunk)
        }
      }

      await result.text // ç­‰å¾…å®Œæˆ
      return fullText
    } catch (error) {
      console.error('AI streaming review failed:', error)
      throw new Error('Failed to stream AI review')
    }
  }

  /**
   * è§£æ AI è¿”å›çš„è¯„è®ºå†…å®¹
   * æœŸæœ›æ ¼å¼ï¼š
   * 10-15:
   * è¯„è®ºå†…å®¹
   * ```
   * ä»£ç ä¿®å¤
   * ```
   * ---
   */
  parseReviewComments(aiResponse: string, filePath: string): ReviewComment[] {
    const comments: ReviewComment[] = []
    const lines = aiResponse.split('\n')
    let currentComment: Partial<ReviewComment> = {}
    let currentContent: string[] = []
    let inCodeBlock = false

    // åŒ¹é…æ ¼å¼: "è¡Œå·: [çº§åˆ«] å†…å®¹" æˆ– "è¡Œå·-è¡Œå·: [çº§åˆ«] å†…å®¹" æˆ– "è¡Œå·:"
    // ä¾‹å¦‚: "12: [ä¸€èˆ¬] å˜é‡å‘½åä¸è§„èŒƒ" æˆ– "10-15:" æˆ– "10:"
    const lineStartPattern = /^(\d+)(?:-(\d+))?:\s*(.*)$/

    for (let i = 0; i < lines.length; i++) {
      const line = lines[i]
      const lineMatch = line.match(lineStartPattern)

      if (lineMatch) {
        // ä¿å­˜ä¹‹å‰çš„è¯„è®º
        if (currentComment.lineNumber && currentContent.length > 0) {
          const content = this.cleanCommentContent(currentContent.join('\n').trim())
          if (content && content !== 'LGTM!') {
            comments.push({
              filePath,
              lineNumber: currentComment.lineNumber,
              lineRangeEnd: currentComment.lineRangeEnd,
              severity: currentComment.severity || 'normal',
              content,
            } as ReviewComment)
          }
        }

        // æå–è¡Œåé¢çš„å†…å®¹ï¼ˆå¯èƒ½åŒ…å« [çº§åˆ«] å’Œæè¿°ï¼‰
        const restOfLine = lineMatch[3] || ''

        // å¼€å§‹æ–°è¯„è®º
        currentComment = {
          lineNumber: parseInt(lineMatch[1]),
          lineRangeEnd: lineMatch[2] ? parseInt(lineMatch[2]) : undefined,
          severity: this.inferSeverity(restOfLine || line),
        }
        currentContent = []
        inCodeBlock = false

        // å¦‚æœè¡Œå·åé¢æœ‰å†…å®¹ï¼ŒåŠ å…¥åˆ°è¯„è®ºå†…å®¹ä¸­
        if (restOfLine.trim()) {
          currentContent.push(restOfLine)
        }
      } else if (currentComment.lineNumber) {
        // æ”¶é›†è¯„è®ºå†…å®¹
        if (line.startsWith('```')) {
          inCodeBlock = !inCodeBlock
          currentContent.push(line)
        } else {
          currentContent.push(line)
        }
      }
    }

    // ä¿å­˜æœ€åä¸€ä¸ªè¯„è®º
    if (currentComment.lineNumber && currentContent.length > 0) {
      const content = this.cleanCommentContent(currentContent.join('\n').trim())
      if (content && content !== 'LGTM!') {
        comments.push({
          filePath,
          lineNumber: currentComment.lineNumber,
          lineRangeEnd: currentComment.lineRangeEnd,
          severity: currentComment.severity || 'normal',
          content,
        } as ReviewComment)
      }
    }

    return comments
  }

  /**
   * æ¸…ç†è¯„è®ºå†…å®¹ï¼Œç§»é™¤çº§åˆ«æ ‡ç­¾å‰ç¼€
   * ä¾‹å¦‚: "[ä¸€èˆ¬] å˜é‡å‘½åä¸è§„èŒƒ" -> "å˜é‡å‘½åä¸è§„èŒƒ"
   */
  private cleanCommentContent(content: string): string {
    // ç§»é™¤å¼€å¤´çš„ [ä¸¥é‡]ã€[ä¸€èˆ¬]ã€[å»ºè®®] ç­‰æ ‡ç­¾
    return content
      .replace(/^\[ä¸¥é‡\]\s*/i, '')
      .replace(/^\[ä¸€èˆ¬\]\s*/i, '')
      .replace(/^\[å»ºè®®\]\s*/i, '')
      .replace(/^\[Critical\]\s*/i, '')
      .replace(/^\[Normal\]\s*/i, '')
      .replace(/^\[Suggestion\]\s*/i, '')
      .trim()
  }

  /**
   * ä»è¯„è®ºå†…å®¹æ¨æ–­ä¸¥é‡çº§åˆ«
   * ä¼˜å…ˆè¯†åˆ«ä¸­æ‹¬å·æ ‡ç­¾ï¼š[ä¸¥é‡]ã€[ä¸€èˆ¬]ã€[å»ºè®®]
   */
  private inferSeverity(content: string): ReviewSeverity {
    const lowerContent = content.toLowerCase()

    // ä¼˜å…ˆåŒ¹é…æ˜ç¡®çš„æ ‡ç­¾æ ¼å¼
    if (content.includes('[ä¸¥é‡]') || content.includes('[Critical]')) {
      return 'critical'
    }
    if (content.includes('[å»ºè®®]') || content.includes('[Suggestion]')) {
      return 'suggestion'
    }
    if (content.includes('[ä¸€èˆ¬]') || content.includes('[Normal]')) {
      return 'normal'
    }

    // å›é€€åˆ°å…³é”®è¯åŒ¹é…
    if (
      lowerContent.includes('ä¸¥é‡') ||
      lowerContent.includes('critical') ||
      lowerContent.includes('security') ||
      lowerContent.includes('vulnerability') ||
      lowerContent.includes('bug') ||
      lowerContent.includes('error') ||
      lowerContent.includes('breaking')
    ) {
      return 'critical'
    }

    if (
      lowerContent.includes('å»ºè®®') ||
      lowerContent.includes('suggestion') ||
      lowerContent.includes('consider') ||
      lowerContent.includes('could') ||
      lowerContent.includes('might')
    ) {
      return 'suggestion'
    }

    return 'normal'
  }
}

export const aiService = new AIService()
