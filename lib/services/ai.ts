/**
 * AI æœåŠ¡æ¨¡å—
 * 
 * æä¾›ä¸å„ç±» AI æ¨¡å‹ï¼ˆOpenAIã€Anthropicã€è‡ªå®šä¹‰ï¼‰çš„äº¤äº’èƒ½åŠ›ï¼Œ
 * ç”¨äºæ‰§è¡Œä»£ç å®¡æŸ¥å¹¶è§£æå®¡æŸ¥ç»“æœã€‚
 */

import { createOpenAI } from '@ai-sdk/openai'
import { createAnthropic } from '@ai-sdk/anthropic'
import { streamText, generateText } from 'ai'
import OpenAI from 'openai'
import type { AIModelConfig, ReviewSeverity } from '@/lib/types'
import { SYSTEM_PROMPT } from '@/lib/prompts'

/**
 * å®¡æŸ¥è¯„è®ºæ¥å£
 */
export interface ReviewComment {
  /** æ–‡ä»¶è·¯å¾„ */
  filePath: string
  /** è¡Œå· */
  lineNumber: number
  /** è¡Œå·èŒƒå›´ç»“æŸï¼ˆå¯é€‰ï¼‰ */
  lineRangeEnd?: number
  /** ä¸¥é‡çº§åˆ« */
  severity: ReviewSeverity
  /** è¯„è®ºå†…å®¹ */
  content: string
  /** diff ä»£ç å—ï¼ˆå¯é€‰ï¼‰ */
  diffHunk?: string
}

/**
 * AI æœåŠ¡ç±»
 * 
 * å°è£…äº†ä¸ AI æ¨¡å‹äº¤äº’çš„æ‰€æœ‰é€»è¾‘ï¼Œæ”¯æŒï¼š
 * - OpenAI (GPT-4o, GPT-4 Turbo ç­‰)
 * - Anthropic Claude (Claude 3.5 Sonnet ç­‰)
 * - è‡ªå®šä¹‰ OpenAI å…¼å®¹ API (å¦‚æ™ºè°± GLMã€æœ¬åœ° Ollama)
 */
export class AIService {
  /**
   * æ‰§è¡Œä»£ç å®¡æŸ¥
   */
  async reviewCode(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    try {
      // è‡ªå®šä¹‰æ¨¡å‹ä½¿ç”¨ OpenAI SDK ç›´æ¥è°ƒç”¨ï¼Œé¿å… Vercel AI SDK å…¼å®¹æ€§é—®é¢˜
      if (modelConfig.provider === 'custom') {
        return await this.reviewCodeWithOpenAISDK(prompt, modelConfig)
      }

      let model

      switch (modelConfig.provider) {
        case 'openai':
          const openaiClient = createOpenAI({ apiKey: modelConfig.apiKey })
          model = openaiClient(modelConfig.modelId)
          break
        case 'claude':
          const anthropicClient = createAnthropic({ apiKey: modelConfig.apiKey })
          model = anthropicClient(modelConfig.modelId)
          break
        default:
          throw new Error(`Unsupported AI provider: ${modelConfig.provider}`)
      }

      const response = await generateText({
        model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: prompt },
        ],
      })

      console.log('AI Response type:', typeof response)
      console.log('AI Response keys:', Object.keys(response))

      if (response.text) {
        return response.text
      }

      console.error('Unexpected AI response format:', response)
      throw new Error('Unexpected AI response format')
    } catch (error) {
      console.error('AI review failed:', error)
      throw new Error('Failed to generate AI review')
    }
  }

  /**
   * ä½¿ç”¨ OpenAI SDK è°ƒç”¨è‡ªå®šä¹‰æ¨¡å‹
   * æ ¹æ® API ç«¯ç‚¹è‡ªåŠ¨åˆ¤æ–­ä½¿ç”¨ OpenAI è¿˜æ˜¯ Anthropic æ ¼å¼
   */
  private async reviewCodeWithOpenAISDK(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    console.log('ğŸ”§ Using custom API for model:', modelConfig.modelId)
    console.log('ğŸ”§ API Endpoint:', modelConfig.apiEndpoint)

    const isAnthropicFormat = modelConfig.apiEndpoint?.includes('anthropic')

    if (isAnthropicFormat) {
      return await this.callAnthropicAPI(prompt, modelConfig, systemPrompt)
    } else {
      return await this.callOpenAIAPI(prompt, modelConfig, systemPrompt)
    }
  }

  /**
   * è°ƒç”¨ OpenAI å…¼å®¹ API
   */
  private async callOpenAIAPI(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT
  ): Promise<string> {
    const client = new OpenAI({
      apiKey: modelConfig.apiKey,
      baseURL: modelConfig.apiEndpoint,
    })

    const response = await client.chat.completions.create({
      model: modelConfig.modelId,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: prompt },
      ],
      max_tokens: modelConfig.maxTokens || 4096,
      temperature: modelConfig.temperature || 0.3,
    })

    console.log('âœ… OpenAI API Response received')
    console.log('ğŸ“Š Usage:', response.usage)

    const content = response.choices[0]?.message?.content
    if (!content) {
      console.error('Empty response from OpenAI API:', response)
      throw new Error('Empty response from OpenAI API')
    }

    return content
  }

  /**
   * è°ƒç”¨ Anthropic å…¼å®¹ APIï¼ˆæ”¯æŒé‡è¯•ï¼‰
   */
  private async callAnthropicAPI(
    prompt: string,
    modelConfig: AIModelConfig,
    systemPrompt: string = SYSTEM_PROMPT,
    retries = 3
  ): Promise<string> {
    // æ™ºèƒ½å¤„ç† API ç«¯ç‚¹
    let apiUrl = modelConfig.apiEndpoint || ''
    if (!apiUrl.endsWith('/v1/messages')) {
      apiUrl = apiUrl.replace(/\/$/, '')
      apiUrl = `${apiUrl}/v1/messages`
    }

    console.log('ğŸ”— Anthropic API URL:', apiUrl)

    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        const response = await fetch(apiUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'x-api-key': modelConfig.apiKey,
            'anthropic-version': '2023-06-01',
          },
          body: JSON.stringify({
            model: modelConfig.modelId,
            max_tokens: modelConfig.maxTokens || 4096,
            system: systemPrompt,
            messages: [{ role: 'user', content: prompt }],
          }),
        })

        if (!response.ok) {
          const errorText = await response.text()
          console.error('Anthropic API error:', response.status, errorText)
          throw new Error(`Anthropic API error: ${response.status}`)
        }

        const data = await response.json()

        console.log('âœ… Anthropic API Response received')
        console.log('ğŸ“Š Usage:', data.usage)
        console.log('ğŸ“‹ Response structure:', Object.keys(data))

        // Anthropic å“åº”æ ¼å¼: { content: [{ type: "text", text: "..." }] }
        if (data.content && Array.isArray(data.content) && data.content.length > 0) {
          const textContent = data.content.find((c: { type: string }) => c.type === 'text')
          if (textContent?.text) {
            return textContent.text
          }
        }

        console.error('Unexpected Anthropic response format:', JSON.stringify(data, null, 2))
        throw new Error('Unexpected Anthropic response format')
      } catch (error) {
        console.error(`âŒ Attempt ${attempt}/${retries} failed:`, error)

        if (attempt < retries) {
          const delay = attempt * 2000
          console.log(`â³ Retrying in ${delay / 1000}s...`)
          await new Promise((resolve) => setTimeout(resolve, delay))
        } else {
          throw error
        }
      }
    }

    throw new Error('All retry attempts failed')
  }

  /**
   * æµå¼ä»£ç å®¡æŸ¥ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰
   */
  async streamReviewCode(
    prompt: string,
    modelConfig: AIModelConfig,
    onChunk?: (chunk: string) => void
  ): Promise<string> {
    try {
      let model

      switch (modelConfig.provider) {
        case 'openai':
          const openaiClient = createOpenAI({
            apiKey: modelConfig.apiKey,
          })
          model = openaiClient(modelConfig.modelId)
          break
        case 'claude':
          const anthropicClient = createAnthropic({
            apiKey: modelConfig.apiKey,
          })
          model = anthropicClient(modelConfig.modelId)
          break
        case 'custom':
          const customClient = createOpenAI({
            apiKey: modelConfig.apiKey,
            baseURL: modelConfig.apiEndpoint,
          })
          model = customClient(modelConfig.modelId)
          break
        default:
          throw new Error(`Unsupported AI provider: ${modelConfig.provider}`)
      }

      const result = await streamText({
        model,
        prompt,
      })

      let fullText = ''
      for await (const chunk of result.textStream) {
        fullText += chunk
        if (onChunk) {
          onChunk(chunk)
        }
      }

      await result.text // ç­‰å¾…å®Œæˆ
      return fullText
    } catch (error) {
      console.error('AI streaming review failed:', error)
      throw new Error('Failed to stream AI review')
    }
  }

  /**
   * è§£æ AI è¿”å›çš„å®¡æŸ¥è¯„è®º
   * 
   * æ”¯æŒæ ¼å¼ï¼š
   * - `è¡Œå·: [çº§åˆ«] å†…å®¹`
   * - `è¡Œå·-è¡Œå·: [çº§åˆ«] å†…å®¹`
   */
  parseReviewComments(aiResponse: string, filePath: string): ReviewComment[] {
    const comments: ReviewComment[] = []
    const lines = aiResponse.split('\n')
    let currentComment: Partial<ReviewComment> = {}
    let currentContent: string[] = []
    let inCodeBlock = false

    const lineStartPattern = /^(\d+)(?:-(\d+))?:\s*(.*)$/

    for (let i = 0; i < lines.length; i++) {
      const line = lines[i]
      const lineMatch = line.match(lineStartPattern)

      if (lineMatch) {
        // ä¿å­˜ä¹‹å‰çš„è¯„è®º
        if (currentComment.lineNumber && currentContent.length > 0) {
          const content = this.cleanCommentContent(currentContent.join('\n').trim())
          if (content && content !== 'LGTM!') {
            comments.push({
              filePath,
              lineNumber: currentComment.lineNumber,
              lineRangeEnd: currentComment.lineRangeEnd,
              severity: currentComment.severity || 'normal',
              content,
            } as ReviewComment)
          }
        }

        const restOfLine = lineMatch[3] || ''
        currentComment = {
          lineNumber: parseInt(lineMatch[1]),
          lineRangeEnd: lineMatch[2] ? parseInt(lineMatch[2]) : undefined,
          severity: this.inferSeverity(restOfLine || line),
        }
        currentContent = []
        inCodeBlock = false

        if (restOfLine.trim()) {
          currentContent.push(restOfLine)
        }
      } else if (currentComment.lineNumber) {
        if (line.startsWith('```')) {
          inCodeBlock = !inCodeBlock
        }
        currentContent.push(line)
      }
    }

    // ä¿å­˜æœ€åä¸€ä¸ªè¯„è®º
    if (currentComment.lineNumber && currentContent.length > 0) {
      const content = this.cleanCommentContent(currentContent.join('\n').trim())
      if (content && content !== 'LGTM!') {
        comments.push({
          filePath,
          lineNumber: currentComment.lineNumber,
          lineRangeEnd: currentComment.lineRangeEnd,
          severity: currentComment.severity || 'normal',
          content,
        } as ReviewComment)
      }
    }

    return comments
  }

  /**
   * æ¸…ç†è¯„è®ºå†…å®¹ï¼Œç§»é™¤çº§åˆ«æ ‡ç­¾å‰ç¼€
   */
  private cleanCommentContent(content: string): string {
    return content
      .replace(/^\[ä¸¥é‡\]\s*/i, '')
      .replace(/^\[ä¸€èˆ¬\]\s*/i, '')
      .replace(/^\[å»ºè®®\]\s*/i, '')
      .replace(/^\[Critical\]\s*/i, '')
      .replace(/^\[Normal\]\s*/i, '')
      .replace(/^\[Suggestion\]\s*/i, '')
      .trim()
  }

  /**
   * ä»è¯„è®ºå†…å®¹æ¨æ–­ä¸¥é‡çº§åˆ«
   */
  private inferSeverity(content: string): ReviewSeverity {
    const lowerContent = content.toLowerCase()

    // åŒ¹é…æ˜ç¡®çš„æ ‡ç­¾
    if (content.includes('[ä¸¥é‡]') || content.includes('[Critical]')) return 'critical'
    if (content.includes('[å»ºè®®]') || content.includes('[Suggestion]')) return 'suggestion'
    if (content.includes('[ä¸€èˆ¬]') || content.includes('[Normal]')) return 'normal'

    // å…³é”®è¯åŒ¹é…
    if (
      lowerContent.includes('ä¸¥é‡') ||
      lowerContent.includes('critical') ||
      lowerContent.includes('security') ||
      lowerContent.includes('vulnerability') ||
      lowerContent.includes('bug') ||
      lowerContent.includes('error') ||
      lowerContent.includes('breaking')
    ) {
      return 'critical'
    }

    if (
      lowerContent.includes('å»ºè®®') ||
      lowerContent.includes('suggestion') ||
      lowerContent.includes('consider') ||
      lowerContent.includes('could') ||
      lowerContent.includes('might')
    ) {
      return 'suggestion'
    }

    return 'normal'
  }
}

export const aiService = new AIService()
